{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our dataset format\n",
    "An event is a list of strings.\n",
    "\n",
    "A sequence is a list of events.\n",
    "\n",
    "A dataset is a list of sequences.\n",
    "\n",
    "Thus, a dataset is a list of lists of lists of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  [\n",
    "    [[\"a\"], [\"a\", \"b\", \"c\"], [\"a\", \"c\"], [\"c\"]],\n",
    "    [[\"a\"], [\"c\"], [\"b\", \"c\"]],\n",
    "    [[\"a\", \"b\"], [\"d\"], [\"c\"], [\"b\"], [\"c\"]],\n",
    "    [[\"a\"], [\"c\"], [\"b\"], [\"c\"]]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations\n",
    "### Subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a simple recursive method that checks if subsequence is a subSequence of mainSequence\n",
    "\"\"\"\n",
    "def isSubsequence(mainSequence, subSequence):\n",
    "    subSequenceClone = list(subSequence) # clone the sequence, because we will alter it\n",
    "    return isSubsequenceRecursive(mainSequence, subSequenceClone) #start recursion\n",
    "\n",
    "\"\"\"\n",
    "Function for the recursive call of isSubsequence, not intended for external calls\n",
    "\"\"\"\n",
    "def isSubsequenceRecursive(mainSequence, subSequenceClone, start=0):\n",
    "    # Check if empty: End of recursion, all itemsets have been found\n",
    "    if (not subSequenceClone):\n",
    "        return True\n",
    "    # retrieves element of the subsequence and removes is from subsequence \n",
    "    firstElem = set(subSequenceClone.pop(0))\n",
    "    # Search for the first itemset...\n",
    "    for i in range(start, len(mainSequence)):\n",
    "        if (set(mainSequence[i]).issuperset(firstElem)):\n",
    "            # and recurse\n",
    "            return isSubsequenceRecursive(mainSequence, subSequenceClone, i + 1)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aSequence = [[\"a\"], [\"b\", \"c\"], [\"d\"], [\"a\", \"e\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"a\"], [\"d\"], [\"e\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"a\"], [\"b\", \"c\"], [\"e\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"a\"], [\"b\", \"d\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of an itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the length of the sequence (sum of the length of the contained itemsets)\n",
    "\"\"\"\n",
    "def sequenceLength(sequence):\n",
    "    return sum(len(i) for i in sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the support of a sequence in a dataset\n",
    "\"\"\"\n",
    "def countSupport (dataset, candidateSequence):\n",
    "    return sum(1 for seq in dataset if isSubsequence(seq, candidateSequence)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['a'], ['a', 'b', 'c'], ['a', 'c'], ['c']],\n",
       " [['a'], ['c'], ['b', 'c']],\n",
       " [['a', 'b'], ['d'], ['c'], ['b'], ['c']],\n",
       " [['a'], ['c'], ['b'], ['c']]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSupport(dataset, [[\"b\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSupport(dataset, [[\"a\"], [\"b\", \"c\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AprioriAll\n",
    "### 1 . Candidate Generation\n",
    "#### For a single pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates one candidate of length k from two candidates of length (k-1) as used in the AprioriAll algorithm\n",
    "\"\"\"\n",
    "def generateCandidatesForPair(cand1, cand2):\n",
    "    cand1Clone = copy.deepcopy(cand1)\n",
    "    cand2Clone = copy.deepcopy(cand2)\n",
    "    # drop the leftmost item from cand1:\n",
    "    if (len (cand1[0]) == 1):\n",
    "        cand1Clone.pop(0)\n",
    "    else:\n",
    "        cand1Clone[0] = cand1Clone[0][1:]\n",
    "    # drop the rightmost item from cand2:\n",
    "    if (len (cand2[-1]) == 1):\n",
    "        cand2Clone.pop(-1)\n",
    "    else:\n",
    "        cand2Clone[-1] = cand2Clone[-1][:-1]\n",
    "    \n",
    "    # if the result is not the same, then we dont need to join\n",
    "    if not cand1Clone == cand2Clone:\n",
    "        return []\n",
    "    else:\n",
    "        newCandidate = copy.deepcopy(cand1)\n",
    "        if (len (cand2[-1]) == 1):\n",
    "            newCandidate.append(cand2[-1])\n",
    "        else:\n",
    "            newCandidate [-1].extend(cand2[-1][-1])\n",
    "        return newCandidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'], ['b', 'c'], ['d', 'e']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [[\"a\"], [\"b\", \"c\"], [\"d\"]]\n",
    "candidateB = [[\"b\", \"c\"], [\"d\", \"e\"]]\n",
    "generateCandidatesForPair(candidateA, candidateB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'], ['b', 'c'], ['d'], ['e']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [[\"a\"], [\"b\", \"c\"], [\"d\"]]\n",
    "candidateC = [[\"b\", \"c\"], [\"d\"], [\"e\"]]\n",
    "generateCandidatesForPair(candidateA, candidateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [[\"a\"], [\"b\", \"c\"], [\"d\"]]\n",
    "candidateD = [[\"a\"], [\"b\", \"c\"], [\"e\"]]\n",
    "generateCandidatesForPair(candidateA, candidateD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a set of candidates (of the last level):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates the set of candidates of length k from the set of frequent sequences with length (k-1)\n",
    "\"\"\"\n",
    "def generateCandidates(lastLevelCandidates):\n",
    "    k = sequenceLength(lastLevelCandidates[0]) + 1\n",
    "    if (k == 2):\n",
    "        flatShortCandidates = [item for sublist2 in lastLevelCandidates for sublist1 in sublist2 for item in sublist1]\n",
    "        result = [[[a, b]] for a in flatShortCandidates for b in flatShortCandidates if b > a]\n",
    "        result.extend([[[a], [b]] for a in flatShortCandidates for b in flatShortCandidates])\n",
    "        return result\n",
    "    else:\n",
    "        candidates = []\n",
    "        for i in range(0, len(lastLevelCandidates)):\n",
    "            for j in range(0, len(lastLevelCandidates)):\n",
    "                newCand = generateCandidatesForPair(lastLevelCandidates[i], lastLevelCandidates[j])\n",
    "                if (not newCand == []):\n",
    "                    candidates.append(newCand)\n",
    "        candidates.sort()\n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example; Lets assume, we know the frequent sequences of level 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastLevelFrequentPatterns = [\n",
    "    [['a', 'b']], \n",
    "    [['b', 'c']], \n",
    "    [['a'], ['b']], \n",
    "    [['a'], ['c']], \n",
    "    [['b'], ['c']],\n",
    "    [['c'], ['b']], \n",
    "    [['c'], ['c']],  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can compute the generate candidates for level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['a'], ['b'], ['c']],\n",
       " [['a'], ['b', 'c']],\n",
       " [['a'], ['c'], ['b']],\n",
       " [['a'], ['c'], ['c']],\n",
       " [['a', 'b'], ['c']],\n",
       " [['a', 'b', 'c']],\n",
       " [['b'], ['c'], ['b']],\n",
       " [['b'], ['c'], ['c']],\n",
       " [['b', 'c'], ['b']],\n",
       " [['b', 'c'], ['c']],\n",
       " [['c'], ['b'], ['c']],\n",
       " [['c'], ['b', 'c']],\n",
       " [['c'], ['c'], ['b']],\n",
       " [['c'], ['c'], ['c']]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newCandidates = generateCandidates(lastLevelFrequentPatterns)\n",
    "newCandidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 . Candidate Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes all direct subsequence for a given sequence.\n",
    "A direct subsequence is any sequence that originates from deleting exactly one item from any event in the original sequence.\n",
    "\"\"\"\n",
    "def generateDirectSubsequences(sequence):\n",
    "    result = []\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if (len(itemset) == 1):\n",
    "            sequenceClone = copy.deepcopy(sequence)\n",
    "            sequenceClone.pop(i)\n",
    "            result.append(sequenceClone)\n",
    "        else:\n",
    "            for j in range(len(itemset)):\n",
    "                sequenceClone = copy.deepcopy(sequence)\n",
    "                sequenceClone[i].pop(j)\n",
    "                result.append(sequenceClone)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prunes the set of candidates generated for length k given all frequent sequence of level (k-1), as done in AprioriAll\n",
    "\"\"\"\n",
    "def pruneCandidates(candidatesLastLevel, candidatesGenerated):\n",
    "    return [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this on example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['a'], ['b'], ['c']],\n",
       " [['a'], ['b', 'c']],\n",
       " [['a'], ['c'], ['b']],\n",
       " [['a'], ['c'], ['c']],\n",
       " [['a', 'b'], ['c']],\n",
       " [['b'], ['c'], ['c']],\n",
       " [['b', 'c'], ['c']],\n",
       " [['c'], ['b'], ['c']],\n",
       " [['c'], ['b', 'c']],\n",
       " [['c'], ['c'], ['b']],\n",
       " [['c'], ['c'], ['c']]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidatesPruned = pruneCandidates(lastLevelFrequentPatterns, newCandidates)\n",
    "candidatesPruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Count Candidates (and filter not frequent ones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['a'], ['b'], ['c']], 3),\n",
       " ([['a'], ['b', 'c']], 2),\n",
       " ([['a'], ['c'], ['b']], 3),\n",
       " ([['a'], ['c'], ['c']], 4),\n",
       " ([['a', 'b'], ['c']], 2),\n",
       " ([['b'], ['c'], ['c']], 2),\n",
       " ([['c'], ['b'], ['c']], 2)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minSupport = 2\n",
    "candidatesCounts = [(i, countSupport(dataset, i)) for i in candidatesPruned]\n",
    "resultLvl = [(i, count) for (i, count) in candidatesCounts if (count >= minSupport)]\n",
    "resultLvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-70-9b056496a826>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-70-9b056496a826>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    print \"Result, lvl 1: \" + str(Overall[0])\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The AprioriAll algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "    verbose: If true, additional information on the mining process is printed (i.e., candidates on each level)\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def apriori(dataset, minSupport, verbose=False):\n",
    "    global numberOfCountingOperations\n",
    "    numberOfCountingOperations = 0\n",
    "    Overall = []\n",
    "    itemsInDataset = sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "    singleItemSequences = [[[item]] for item in itemsInDataset]\n",
    "    singleItemCounts = [(i, countSupport(dataset, i)) for i in singleItemSequences if countSupport(dataset, i) >= minSupport]\n",
    "    Overall.append(singleItemCounts)\n",
    "    print \"Result, lvl 1: \" + str(Overall[0])\n",
    "    k = 1\n",
    "    while (True):\n",
    "        if not Overall [k - 1]:\n",
    "            break\n",
    "        # 1. Candidate generation\n",
    "        candidatesLastLevel = [x[0] for x in Overall[k - 1]]\n",
    "        candidatesGenerated = generateCandidates (candidatesLastLevel)\n",
    "        # 2. Candidate pruning (using a \"containsall\" subsequences)\n",
    "        candidatesPruned = [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]\n",
    "        # 3. Candidate checking\n",
    "        candidatesCounts = [(i, countSupport(dataset, i)) for i in candidatesPruned]\n",
    "        resultLvl = [(i, count) for (i, count) in candidatesCounts if (count >= minSupport)]\n",
    "        if verbose:\n",
    "            print \"Candidates generated, lvl \" + str(k + 1) + \": \" + str(candidatesGenerated)\n",
    "            print \"Candidates pruned, lvl \" + str(k + 1) + \": \" + str(candidatesPruned)\n",
    "            print \"Result, lvl \" + str(k + 1) + \": \" + str(resultLvl)\n",
    "        Overall.append(resultLvl)\n",
    "        k = k + 1\n",
    "    # \"flatten\" Overall\n",
    "    Overall = Overall [:-1]\n",
    "    Overall = [item for sublist in Overall for item in sublist]\n",
    "    return Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori(dataset, 2, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PrefixSpan\n",
    "\n",
    "### Project a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Projects a sequence according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    sequence: the sequence the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    If the sequence does not contain the prefix, then None.\n",
    "    Otherwise, a new sequence starting from the position of the prefix, including the itemset that includes the prefix\n",
    "\"\"\"\n",
    "def projectSequence(sequence, prefix, newEvent):\n",
    "    result = None\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if result is None:\n",
    "            if (not newEvent) or i > 0:\n",
    "                if (all(x in itemset for x in prefix)):\n",
    "                    result = [list(itemset)]\n",
    "        else:\n",
    "            result.append(copy.copy(itemset))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [[\"a\"], [\"b\", \"c\"], [\"a\", \"c\"], [\"c\"]]\n",
    "projectSequence(seq, [\"b\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectSequence(seq, [\"a\", \"c\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectSequence(seq, [\"a\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectSequence(seq, [\"a\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Projects a dataset according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    dataset: the dataset the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    A (potentially empty) list of sequences\n",
    "\"\"\"\n",
    "def projectDatabase(dataset, prefix, newEvent):\n",
    "    projectedDB = []\n",
    "    for sequence in dataset:\n",
    "        seqProjected = projectSequence(sequence, prefix, newEvent)\n",
    "        if not seqProjected is None:\n",
    "            projectedDB.append(seqProjected)\n",
    "    return projectedDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetProject = [\n",
    "            [[\"a\"], [\"a\", \"b\", \"c\"], [\"a\", \"c\"], [\"d\"], [\"c\", \"f\"]],\n",
    "            [[\"a\", \"d\"], [\"c\"], [\"b\", \"c\"], [\"a\", \"e\"]],\n",
    "            [[\"e\", \"f\"], [\"a\", \"b\"], [\"d\", \"f\"], [\"d\"], [\"b\"]],\n",
    "            [[\"e\"], [\"g\"], [\"a\", \"f\"], [\"c\"], [\"b\"], [\"c\"]]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectDatabase(datasetProject, [\"c\"], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some more utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates a list of all items that are contained in a dataset\n",
    "\"\"\"\n",
    "def generateItems(dataset):\n",
    "    return sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "\n",
    "\"\"\"\n",
    "Computes a defaultdict that maps each item in the dataset to its support\n",
    "\"\"\"\n",
    "def generateItemSupports(dataset, ignoreFirstEvent=False, prefix=[]):\n",
    "    result = defaultdict(int)\n",
    "    for sequence in dataset:\n",
    "        if ignoreFirstEvent:\n",
    "            sequence = sequence[1:]\n",
    "        cooccurringItems = set()\n",
    "        for itemset in sequence:\n",
    "            if all(x in itemset for x in prefix):\n",
    "                for item in itemset:\n",
    "                    if not item in prefix:\n",
    "                        cooccurringItems.add(item)\n",
    "        for item in cooccurringItems:\n",
    "            result [item] += 1\n",
    "    return sorted(result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "a[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The PrefixSpan algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def prefixSpan(dataset, minSupport):\n",
    "    result = []\n",
    "    itemCounts = generateItemSupports(dataset)\n",
    "    for item, count in itemCounts:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = [[item]]\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], False), minSupport, newPrefix))\n",
    "    return result\n",
    "\n",
    "def prefixSpanInternal(dataset, minSupport, prevPrefixes=[]):\n",
    "    result = []\n",
    "    \n",
    "    # Add a new item to the last element (==same time)\n",
    "    itemCountSameEvent = generateItemSupports(dataset, False, prefix=prevPrefixes[-1])\n",
    "    for item, count in itemCountSameEvent:\n",
    "        if (count >= minSupport) and item > prevPrefixes[-1][-1]:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix[-1].append(item)\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, newPrefix[-1], False), minSupport, newPrefix))\n",
    "        \n",
    "    # Add a new event to the prefix\n",
    "    itemCountSubsequentEvents = generateItemSupports(dataset, True)\n",
    "    for item, count in itemCountSubsequentEvents:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix.append([item])\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], True), minSupport, newPrefix))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixSpan(dataset, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Filter for closed and maximal patterns\n",
    "### Closed patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of closed frequent sequence (as a list)\n",
    "This is only a very simplistic (naive) implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterClosed(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence(supersequence, subsequence) and (countSeq == countSubSeq) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = prefixSpan(dataset, 2)\n",
    "filterClosed(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of maximal frequent sequence (as a list)\n",
    "This is only a very naive implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterMaximal(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence (supersequence, subsequence) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = prefixSpan (dataset, 2)\n",
    "filterMaximal(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application example: Wikispeedia\n",
    "Now we try to find some sequential patterns in a real world dataset: Wikispeedia\n",
    "\n",
    "First load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "sequences = []\n",
    "\n",
    "# from https://snap.stanford.edu/data/wikispeedia.html\n",
    "for line in csv.reader((row for row in open(\"data/paths_finished.tsv\") if not row.startswith('#')), delimiter='\\t'):\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    # for simplicity, let us remove back clicks\n",
    "    seq = line[3].split(\";\")\n",
    "    # for simplicity, let us remove back clicks\n",
    "    seq = [x for x in seq if x != \"<\"]\n",
    "    sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert this to the list of list of lists that we use as a dataformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikispeediaData=[]\n",
    "for seq in sequences:\n",
    "    newSeq = []\n",
    "    for item in seq:\n",
    "        newSeq.append([item])\n",
    "    wikispeediaData.append(newSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time prefixSpan (wikispeediaData, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time apriori(wikispeediaData, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
